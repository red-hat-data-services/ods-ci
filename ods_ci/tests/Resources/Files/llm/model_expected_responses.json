{
    "queries": [
        {
            "query_text": "At what temperature does water boil?",
            "models": {
                "flan-t5-small-caikit": {
                    "response_tokens":  5,
                    "response_text": "74 degrees F",
                    "streamed_response_text":   "{'details':{'input_token_count':'8'}}{'tokens':[{'text':'▁','logprob':-1.6961838006973267}],'details':{'generated_tokens':1}}{'generated_text':'74','tokens':[{'text':'74','logprob':-3.250730037689209}],'details':{'generated_tokens':2}}{'generated_text':'degrees','tokens':[{'text':'▁degrees','logprob':-0.4324559271335602}],'details':{'generated_tokens':3}}{'generated_text':'F','tokens':[{'text':'▁F','logprob':-1.361091136932373}],'details':{'generated_tokens':4}}{'tokens':[{'text':'\u003c/s\u003e','logprob':-0.010431881994009018}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':5}}",
                    "tgis-runtime":{
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 8, 'tokens': [ '▁At', '▁what', '▁temperature', '▁does', '▁water', '▁boil', '?', '\u003c/s\u003e' ] } ] }"
                    }
                },
                "flan-t5-small-hf": {
                    "response_tokens":  5,
                    "response_text": "74 degrees F",
                    "streamed_response_text":   "{'details':{'input_token_count':'8'}}{'tokens':[{'text':'▁','logprob':-1.6961838006973267}],'details':{'generated_tokens':1}}{'generated_text':'74','tokens':[{'text':'74','logprob':-3.250730037689209}],'details':{'generated_tokens':2}}{'generated_text':'degrees','tokens':[{'text':'▁degrees','logprob':-0.4324559271335602}],'details':{'generated_tokens':3}}{'generated_text':'F','tokens':[{'text':'▁F','logprob':-1.361091136932373}],'details':{'generated_tokens':4}}{'tokens':[{'text':'\u003c/s\u003e','logprob':-0.010431881994009018}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':5}}",
                    "tgis-runtime":{
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 8, 'tokens': [ '▁At', '▁what', '▁temperature', '▁does', '▁water', '▁boil', '?', '\u003c/s\u003e' ] } ] }"
                    }                },
                "bloom-560m-caikit": {
                    "response_tokens":  20,
                    "response_text": "The temperature of water boiling depends on the temperature of the water. The boiling point of water is the"
                },
                "flan-t5-large": {
                    "response_tokens":  7,
                    "response_text": "212 ° f",
                    "streamed_response_text":   "{  'details': {    'input_token_count': '8'  }}{  'tokens': [    {      'text': '▁',      'logprob': -1.2747352123260498    }  ],  'details': {    'generated_tokens': 1  }}{  'generated_text': '212',  'tokens': [    {      'text': '212',      'logprob': -1.0382558107376099    }  ],  'details': {    'generated_tokens': 2  }}{  'generated_text': ' ',  'tokens': [    {      'text': '▁',      'logprob': -0.8835393786430359    }  ],  'details': {    'generated_tokens': 3  }}{  'generated_text': '°',  'tokens': [    {      'text': '°',      'logprob': -0.6830151677131653    }  ],  'details': {    'generated_tokens': 4  }}{  'generated_text': ' ',  'tokens': [    {      'text': '▁',      'logprob': -0.8991543650627136    }  ],  'details': {    'generated_tokens': 5  }}{  'generated_text': 'f',  'tokens': [    {      'text': 'f',      'logprob': -0.44153422117233276    }  ],  'details': {    'generated_tokens': 6  }}{  'tokens': [    {      'text': '\u003c/s\u003e',      'logprob': -0.015602776780724525    }  ],  'details': {    'finish_reason': 'EOS_TOKEN',    'generated_tokens': 7  }}"
                },
                "mpt-7b-instruct2": {
                    "response_tokens": 20,
                    "response_text": "\nWater boils at 100 degrees Celsius (or 212 degrees Fahrenheit).\nWhat",
                    "streamed_response_text": "{'inputTokenCount': 7}{'generatedTokenCount': 2,'text': '\nWate'}{'generatedTokenCount': 3,'text': 'r b'}{'generatedTokenCount': 4,'text': 'oil'}{'generatedTokenCount': 5,'text': 's a'}{'generatedTokenCount': 6,'text': 't 10'}{'generatedTokenCount': 7,'text': '0 degree'}{'generatedTokenCount': 8,'text': 's '}{'generatedTokenCount': 9,'text': 'Cel'}{'generatedTokenCount': 10,'text': 'siu'}{'generatedTokenCount': 11,'text': 's '}{'generatedTokenCount': 12,'text': '(o'}{'generatedTokenCount': 13,'text': 'r 21'}{'generatedTokenCount': 14,'text': '2 degree'}{'generatedTokenCount': 15,'text': 's '}{'generatedTokenCount': 16,'text': 'Fahre'}{'generatedTokenCount': 17,'text': 'nhei'}{'generatedTokenCount': 18,'text': 't)'}{'generatedTokenCount': 19,'text': '.'}{'generatedTokenCount': 20,'text': '\nWhat','stopReason': 'MAX_TOKENS'}",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 7, 'tokens': [ 'At', 'Ġwhat', 'Ġtemperature', 'Ġdoes', 'Ġwater', 'Ġboil', '?' ] } ] }"
                    }
                },
                "llama-2-13b-chat": {
                    "response_tokens": 20,
                    "response_text": "\n\nWater boils at 100 degrees Celsius or 212",
                    "streamed_response_text": "{ 'inputTokenCount': 9 } { 'generatedTokenCount': 2, 'text': '\n' } { 'generatedTokenCount': 3, 'text': '\n' } { 'generatedTokenCount': 4, 'text': 'Wate' } { 'generatedTokenCount': 5, 'text': 'r b' } { 'generatedTokenCount': 6, 'text': 'oil' } { 'generatedTokenCount': 7, 'text': 's a' } { 'generatedTokenCount': 8, 'text': 't' } { 'generatedTokenCount': 9, 'text': ' ' } { 'generatedTokenCount': 10, 'text': '1' } { 'generatedTokenCount': 11, 'text': '0' } { 'generatedTokenCount': 12, 'text': '0 degree' } { 'generatedTokenCount': 13, 'text': 's Ce' } { 'generatedTokenCount': 14, 'text': 'ls' } { 'generatedTokenCount': 15, 'text': 'iu' } { 'generatedTokenCount': 16, 'text': 's o' } { 'generatedTokenCount': 17, 'text': 'r' } { 'generatedTokenCount': 18, 'text': ' ' } { 'generatedTokenCount': 19, 'text': '2' } { 'generatedTokenCount': 20, 'text': '12', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{'responses':[{'tokenCount':9,'tokens':['\\u003cs\\u003e','▁At','▁what','▁temperature','▁does','▁water','▁bo','il','?']}]}"
                    }
                },
                "granite-8b-code-base": {
                    "response_tokens": 20,
                    "response_text": "\n\nWater boils at 100 degrees Celsius or 212",
                    "streamed_response_text": "{ 'inputTokenCount': 8 } { 'generatedTokenCount': 2, 'text': '\n' } { 'generatedTokenCount': 3, 'text': '\n' } { 'generatedTokenCount': 4, 'text': 'Wate' } { 'generatedTokenCount': 5, 'text': 'r b' } { 'generatedTokenCount': 6, 'text': 'oil' } { 'generatedTokenCount': 7, 'text': 's a' } { 'generatedTokenCount': 8, 'text': 't' } { 'generatedTokenCount': 9, 'text': ' ' } { 'generatedTokenCount': 10, 'text': '1' } { 'generatedTokenCount': 11, 'text': '0' } { 'generatedTokenCount': 12, 'text': '0 degree' } { 'generatedTokenCount': 13, 'text': 's Ce' } { 'generatedTokenCount': 14, 'text': 'ls' } { 'generatedTokenCount': 15, 'text': 'iu' } { 'generatedTokenCount': 16, 'text': 's o' } { 'generatedTokenCount': 17, 'text': 'r' } { 'generatedTokenCount': 18, 'text': ' ' } { 'generatedTokenCount': 19, 'text': '2' } { 'generatedTokenCount': 20, 'text': '12', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{'responses':[{'tokenCount':9,'tokens':['\\u003cs\\u003e','▁At','▁what','▁temperature','▁does','▁water','▁bo','il','?']}]}"
                    }
                },
                "merlinite-7b-lab": {
                    "response_tokens": 20,
                    "response_text": "\n\nWater boils at 100 degrees Celsius or 212",
                    "streamed_response_text": "{ 'inputTokenCount': 8 } { 'generatedTokenCount': 2, 'text': '\n' } { 'generatedTokenCount': 3, 'text': '\n' } { 'generatedTokenCount': 4, 'text': 'Wate' } { 'generatedTokenCount': 5, 'text': 'r b' } { 'generatedTokenCount': 6, 'text': 'oil' } { 'generatedTokenCount': 7, 'text': 's a' } { 'generatedTokenCount': 8, 'text': 't' } { 'generatedTokenCount': 9, 'text': ' ' } { 'generatedTokenCount': 10, 'text': '1' } { 'generatedTokenCount': 11, 'text': '0' } { 'generatedTokenCount': 12, 'text': '0 degree' } { 'generatedTokenCount': 13, 'text': 's Ce' } { 'generatedTokenCount': 14, 'text': 'ls' } { 'generatedTokenCount': 15, 'text': 'iu' } { 'generatedTokenCount': 16, 'text': 's o' } { 'generatedTokenCount': 17, 'text': 'r' } { 'generatedTokenCount': 18, 'text': ' ' } { 'generatedTokenCount': 19, 'text': '2' } { 'generatedTokenCount': 20, 'text': '12', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{'responses':[{'tokenCount':9,'tokens':['\\u003cs\\u003e','▁At','▁what','▁temperature','▁does','▁water','▁bo','il','?']}]}"
                    }
                }
            }
        },
        {
            "query_text": "This are an very wrong phraxe",
            "models": {
                "flan-t5-large-grammar-synthesis-caikit": {
                    "response_tokens":  9,
                    "response_text": "This is a very wrong phrase.",
                    "streamed_response_text":   "{'details':{'input_token_count':'10'}}{'generated_text':'This','tokens':[{'text':'▁This','logprob':<logprob_removed>}],'details':{'generated_tokens':1}}{'generated_text':'is','tokens':[{'text':'▁is','logprob':<logprob_removed>}],'details':{'generated_tokens':2}}{'generated_text':'','tokens':[{'text':'▁','logprob':<logprob_removed>}],'details':{'generated_tokens':3}}{'generated_text':'a','tokens':[{'text':'a','logprob':<logprob_removed>}],'details':{'generated_tokens':4}}{'generated_text':'very','tokens':[{'text':'▁very','logprob':<logprob_removed>}],'details':{'generated_tokens':5}}{'generated_text':'wrong','tokens':[{'text':'▁wrong','logprob':<logprob_removed>}],'details':{'generated_tokens':6}}{'generated_text':'phrase','tokens':[{'text':'▁phrase','logprob':<logprob_removed>}],'details':{'generated_tokens':7}}{'generated_text':'.','tokens':[{'text':'.','logprob':<logprob_removed>}],'details':{'generated_tokens':8}}{'tokens':[{'text':'</s>','logprob':<logprob_removed>}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':9}}"
                }
            }
        },
        {
            "query_text": "Elementary Watson! Translate to French",
            "models": {
                "mt0-xxl-hf": {
                    "response_tokens":  13,
                    "response_text": "Watson, c'est très simple !",
                    "streamed_response_text":   "{ 'inputTokenCount': 9 } { 'generatedTokenCount': 2, 'text': 'Watson' } { 'generatedTokenCount': 3, 'text': ',' } { 'generatedTokenCount': 4, 'text': ' c' } { 'generatedTokenCount': 5, 'text': \"'\" } { 'generatedTokenCount': 6, 'text': 'est' } { 'generatedTokenCount': 7, 'text': ' ' } { 'generatedTokenCount': 8, 'text': 'trè' } { 'generatedTokenCount': 9, 'text': 's' } { 'generatedTokenCount': 10, 'text': ' simple' } { 'generatedTokenCount': 11, 'text': ' ' } { 'generatedTokenCount': 12, 'text': '!' } { 'generatedTokenCount': 13, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime":{
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 9,       'tokens': [         '▁',         'Elementary',         '▁',         'Watson',         '!',         '▁Translate',         '▁to',         '▁French',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "translate English to German: How old are you?",
            "models":  {
                "flan-t5-xl-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 11,       'tokens': [         '▁translate',         '▁English',         '▁to',         '▁German',         ':',         '▁How',         '▁old',         '▁are',         '▁you',         '?',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                },
                "flan-t5-xxl-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 11, 'tokens': [ '▁translate', '▁English', '▁to', '▁German', ':', '▁How', '▁old', '▁are', '▁you', '?', '\u003c/s\u003e' ] } ] }"
                    }
                },
                "flan-ul2-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 11, 'tokens': [ '▁translate', '▁English', '▁to', '▁German', ':', '▁How', '▁old', '▁are', '▁you', '?', '\u003c/s\u003e' ] } ] }"
                    }

                }
            }
        },
        {
            "query_text": "桜の木についての話を書く",
            "models": {
                "elyza-japanese": {
                    "response_tokens":  20,
                    "response_text": "。\n桜の木は、桜の花が咲くと",
                    "streamed_response_text":   "{ 'inputTokenCount': 16 } { 'generatedTokenCount': 2, 'text': '。' } { 'generatedTokenCount': 5, 'text': '\n' } { 'generatedTokenCount': 6, 'text': '桜' } { 'generatedTokenCount': 7, 'text': 'の' } { 'generatedTokenCount': 8, 'text': '木' } { 'generatedTokenCount': 9, 'text': 'は' } { 'generatedTokenCount': 12, 'text': '、' } { 'generatedTokenCount': 13, 'text': '桜' } { 'generatedTokenCount': 14, 'text': 'の' } { 'generatedTokenCount': 15, 'text': '花' } { 'generatedTokenCount': 18, 'text': 'が' } { 'generatedTokenCount': 19, 'text': '咲' } { 'generatedTokenCount': 20, 'text': 'くと', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime":{
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 16,       'tokens': [         '\u003cs\u003e',         '▁',         '\u003c0xE6\u003e',         '\u003c0xA1\u003e',         '\u003c0x9C\u003e',         'の',         '木',         'に',         'つ',         'い',         'て',         'の',         '話',         'を',         '書',         'く'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "write a python function to print the numbers from 1 to 10",
            "models": {
                "codellama-34b-instruct-hf": {
                    "response_tokens": 20,
                    "response_text": "0.\n\n\ndef print_numbers(n):\n    for i in range(1",
                    "streamed_response_text": "{'inputTokenCount':16}{'generatedTokenCount':2,'text':'0'}{'generatedTokenCount':3,'text':'.'}{'generatedTokenCount':4,'text':''}{'generatedTokenCount':5,'text':''}{'generatedTokenCount':6,'text':'de'}{'generatedTokenCount':7,'text':'fprin'}{'generatedTokenCount':8,'text':'t'}{'generatedTokenCount':9,'text':'_number'}{'generatedTokenCount':10,'text':'s'}{'generatedTokenCount':11,'text':'('}{'generatedTokenCount':12,'text':'n)'}{'generatedTokenCount':13,'text':':'}{'generatedTokenCount':14,'text':''}{'generatedTokenCount':15,'text':'fo'}{'generatedTokenCount':16,'text':'r'}{'generatedTokenCount':17,'text':'ii'}{'generatedTokenCount':18,'text':'nrang'}{'generatedTokenCount':19,'text':'e'}{'generatedTokenCount':20,'text':'(1','stopReason':'MAX_TOKENS'}"
                }
            }
        },
        {
            "query_text": "I am frustrated because of long wait times and unresponsive helpdesk teams, causing delays in issue resolution.",
            "models": {
                "flan-t5-xl-hf-ptuned": {
                    "response_tokens": 2,
                    "response_text": "complaint",
                    "streamed_response_text": "{   'inputTokenCount': 24 } {   'generatedTokenCount': 1,   'text': 'complaint' } {   'generatedTokenCount': 2,   'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 24,       'tokens': [         '▁I',         '▁am',         '▁frustrated',         '▁because',         '▁of',         '▁long',         '▁wait',         '▁times',         '▁and',         '▁un',         'responsive',         '▁help',         'des',         'k',         '▁teams',         ',',         '▁',         'causing',         '▁delays',         '▁in',         '▁issue',         '▁resolution',         '.',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "I am delighted to see how much helpful the helpdesk team is.",
            "models": {
                "flan-t5-xl-hf-ptuned": {
                    "response_tokens": 3,
                    "response_text": "no complaint",
                    "streamed_response_text": "{   'inputTokenCount': 16 } {   'generatedTokenCount': 1,   'text': 'no' } {   'generatedTokenCount': 2,   'text': ' complaint' } {   'generatedTokenCount': 3,   'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": ""
                    }
                }
            }
        },
        {
            "query_text": "{'role': 'system','content': 'You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.'},{'role': 'user','content': 'Compose a poem that explains the concept of recursion in programming.'}",
            "models": {
                "gpt2": {
                    "vllm-runtime": {
                        "chat-completions_response_text": "A friend of mine came over to the house to play with his wife. He was asleep, and he felt like he'd been hit by a speeding car. He's a big guy. He's like the kind of guy who may not have a very good head, but he's big enough to stand up at a table and read something. I was like, \"I'm going to play with this.\"\n\nThat's where I started playing with my car. It was something I never dreamed of doing, but I'd never imagined that it would be such a big deal.\n\nWe started playing with it. When I was about 12, we started playing with it to see how it would turn out. I was 26, and I was playing it for the first time for the first time ever. It was fun. I remember thinking it was like a different game than I had ever played before. I remember thinking the first time we played would be like, \"Oh my god, I've never played a game like this before before.\"\n\nIt was surreal. I was in my 20s at the time. We got to have a party in my house at the time. I was sitting in the living room with my friend, who's 28. We're from Dallas, and his wife is a pretty big girl. He's about 6 feet tall and 250 pounds. On the phone with his friend said, \"Dad, is it possible you'll be able to do this without your beard?\" I was like, \"Absolutely, actually.\" I thought, \"I'm going to do it.\"\n\nI finally did it and it turned out pretty well. I was able to take our photo with our friend, and he got excited and started laughing. He was like, \"That's awesome.\" I sat in his living room for two hours and made sure he was really excited. He was really excited. We ended up having a workshop and we have a lot of stuff to do.\n\nHe just started playing. It's been amazing. I'm like, \"It's going to be huge.\" At first I was like, \"Wow, my god that's amazing.\" I was like, \"Wow, my God that's awesome.\" He's like, \"I'm so excited about this!\" He was like, \"Oh my god, I can't wait to do it!\"\n\nHe had that awesome physique. He was super skinny. He was like, \"I'm so excited about it.\" He was like, \"Really?\" I was like, \"Yeah, I'm so excited! I'm so excited.\" We did it for two weeks and it turned out pretty well.\n\nHe's like, \"I hope it stays that way.\" I was like, \"I hope it stays that way.\" He was like, \"Oh my god, I've never even played with a computer before!\" I was like, \"Yeah, it's just fun to play with a computer.\" He was like, \"Oh my god, I can't wait to play with a computer!\" He was like, \"It's just a cool thing to do!\"\n\nI was doing it with my friend's dog, a puppy.\n\nI was doing it with my friend's dog. People said, \"You think that's cool?\" I said, \"Yeah, that's cool.\" We had the dog. He was a little bit shy and it was a little bit intimidating and scary.\n\nWe played it twice. It was like a game. He was like, \"Oh my God I've never played with a computer before!\" I was like, \"I hope it stays that way.\" He was like, \"Yeah, it's just a cool thing to do!\" He was like, \"Oh my god, I can't wait to do it!\"\n\nWe played it again on the bus, on the weekend.\n\nWe played it again on the weekend.\n\nThen we went to the store and bought a new Canon 5D Mark II.\n\nI couldn't believe what the customer was saying. I was like, \"That sounds amazing!\" He was like, \"That's amazing!\"\n\nHe was like, \"Wow! That's awesome!\" So we were like, \"Wow! That looks awesome!\" He's like, \"Yeah, that looks awesome!\" I was like, \"Wow! That looks awesome! That looks awesome!\"\n\nWe played it twice again.\n\nI was like, \"Wow! That sounds awesome!\" He was like, \"Wow! That sounds awesome! That sounds awesome!\" I was like, \"Wow! That looks awesome!\"\n\nHe was like, \"Wow! That sounds awesome! That looks awesome!\"\n\nI was just like, \"Wow! That looks awesome! That looks awesome!\" He was like"
                    }
                }
            }
        },
        {
            "query_text": "{'role': 'user' , 'content' : '。桜の木は、桜の花が咲くと'}",
            "models": {
                "elyza-japanese":{
                    "vllm-runtime": {
                        "chat-completions_response_text": "{\"id\":\"cmpl-53b80efcc34f4dfcbd0b325ff0777051\",\"object\":\"chat.completion\",\"created\":1716276132,\"model\":\"e\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"  桜の木は、桜の花が咲くと芽吹きが始まります。つぼみは膨らみ、色が開き、準備ができた芽を支えます。葉が落ちるまでの間に、芽かきをして、芽だけを残します。\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":29,\"total_tokens\":181,\"completion_tokens\":152}}"
                    }
                }
            }
        },
        {
            "query_text": "。桜の木は、桜の花が咲くと",
            "models": {
                "elyza-japanese":{
                    "vllm-runtime": {
                        "completions_response_text": "{\"id\":\"cmpl-8faf5129deac4da88d002e4526fd88a4\",\"object\":\"text_completion\",\"created\":1716279480,\"model\":\"e\",\"choices\":[{\"index\":0,\"text\":\"徒長する。つまり芽吹\",\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"promp21,\"total_tokens\":37,\"completion_tokens\":16}}"
                    }
                }
            }
        },
        {
            "query_text": "San Francisco is a",
            "models": {
                "llama-2-13b-chat":{
                    "vllm-runtime": {
                        "completions_response_text": "{\"object\":\"text_completion\",\"created\":,\"model\":\"llama-2-13b-chat\",\"choices\":[{\"index\":0,\"text\":\" beautiful city that is full of life and energy. Located along the San Francisco\",\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":5,\"total_tokens\":21,\"completion_tokens\":16}}"
                    }
                },
                "granite-8b-code-base":{
                    "vllm-runtime": {
                        "completions_response_text": "{\"object\":\"text_completion\",\"created\":,\"model\":\"granite-8b-code-base\",\"choices\":[{\"index\":0,\"text\":\" city in California, one of the most populous cities in the United States\",\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":5,\"total_tokens\":20,\"completion_tokens\":16}}"
                    }
                },
                "merlinite-7b-lab":{
                    "vllm-runtime": {
                        "completions_response_text": "{\"object\":\"text_completion\",\"created\":,\"model\":\"granite-8b-code-base\",\"choices\":[{\"index\":0,\"text\":\" city in California, one of the most populous cities in the United States\",\"logprobs\":null,\"finish_reason\":\"length\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":5,\"total_tokens\":20,\"completion_tokens\":16}}"
                    }
                },
                "e5-mistral-7b":{
                    "vllm-runtime": {
                        "embeddings_response_text": "The actual embedded output is too large, and we don't check or match the response"
                    }
                }
            }
        },
        {
            "query_text": "{'role': 'user' , 'content' : 'Say this is a test!'}",
            "models": {
                "llama-2-13b-chat":{
                    "vllm-runtime": {
                        "chat-completions_response_text": "{\"object\":\"chat.completion\",\"created\":,\"model\":\"llama-2-13b-chat\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"  This is a test!\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":15,\"total_tokens\":22,\"completion_tokens\":7}}"
                    }
                },
                "granite-8b-code-base":{
                    "vllm-runtime": {
                        "chat-completions_response_text": "{\"object\":\"chat.completion\",\"created\":,\"model\":\"llama-2-13b-chat\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"  This is a test!\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":15,\"total_tokens\":22,\"completion_tokens\":7}}"
                    }
                },
                "merlinite-7b-lab":{
                    "vllm-runtime": {
                        "chat-completions_response_text": "{\"object\":\"chat.completion\",\"created\":,\"model\":\"llama-2-13b-chat\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"  This is a test!\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":15,\"total_tokens\":22,\"completion_tokens\":7}}"
                    }
                }
            }
        }
    ],
    "model-info": {
        "flan-t5-small-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-small-caikit": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "mt0-xxl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 2048, 'maxNewTokens': 1024 }"
        },
        "flan-t5-xl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-xl-hf-ptuned": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-xxl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 2048, 'maxNewTokens': 1024 }"
        },
        "flan-ul2-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "elyza-japanese" : {
            "tgis-runtime": "{   'maxSequenceLength': 4096,   'maxNewTokens': 1024 }"
        },
        "mpt-7b-instruct2":{
            "tgis-runtime": "{     'maxSequenceLength': 2048,     'maxNewTokens': 1024   }"
        },
        "llama-2-13b-chat-hf":{
            "tgis-runtime": "{ 'maxSequenceLength': 4096,'maxNewTokens': 1024}"
        },
        "granite-8b-code-base":{
            "tgis-runtime": "{ 'maxSequenceLength': 4096,'maxNewTokens': 1024}"
        },
        "merlinite-7b-lab": {
            "tgis-runtime": "{ 'maxSequenceLength': 4096,'maxNewTokens': 1024}"
        }
    }
}
