{
    "queries": [
        {
            "query_text": "At what temperature does water boil?",
            "models": {
                "flan-t5-small-caikit": {
                    "response_tokens":  5,
                    "response_text": "74 degrees F",
                    "streamed_response_text":   "{'details':{'input_token_count':'8'}}{'tokens':[{'text':'▁','logprob':-1.6961838006973267}],'details':{'generated_tokens':1}}{'generated_text':'74','tokens':[{'text':'74','logprob':-3.250730037689209}],'details':{'generated_tokens':2}}{'generated_text':'degrees','tokens':[{'text':'▁degrees','logprob':-0.4324559271335602}],'details':{'generated_tokens':3}}{'generated_text':'F','tokens':[{'text':'▁F','logprob':-1.361091136932373}],'details':{'generated_tokens':4}}{'tokens':[{'text':'\u003c/s\u003e','logprob':-0.010431881994009018}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':5}}",
                    "tgis-runtime":{
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 8, 'tokens': [ '▁At', '▁what', '▁temperature', '▁does', '▁water', '▁boil', '?', '\u003c/s\u003e' ] } ] }"
                    }
                },
                "flan-t5-small-hf": {
                    "response_tokens":  5,
                    "response_text": "74 degrees F",
                    "streamed_response_text":   "{'details':{'input_token_count':'8'}}{'tokens':[{'text':'▁','logprob':-1.6961838006973267}],'details':{'generated_tokens':1}}{'generated_text':'74','tokens':[{'text':'74','logprob':-3.250730037689209}],'details':{'generated_tokens':2}}{'generated_text':'degrees','tokens':[{'text':'▁degrees','logprob':-0.4324559271335602}],'details':{'generated_tokens':3}}{'generated_text':'F','tokens':[{'text':'▁F','logprob':-1.361091136932373}],'details':{'generated_tokens':4}}{'tokens':[{'text':'\u003c/s\u003e','logprob':-0.010431881994009018}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':5}}",
                    "tgis-runtime":{
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 8, 'tokens': [ '▁At', '▁what', '▁temperature', '▁does', '▁water', '▁boil', '?', '\u003c/s\u003e' ] } ] }"
                    }                },
                "bloom-560m-caikit": {
                    "response_tokens":  20,
                    "response_text": "The temperature of water boiling depends on the temperature of the water. The boiling point of water is the"
                },
                "flan-t5-large": {
                    "response_tokens":  7,
                    "response_text": "212 ° f",
                    "streamed_response_text":   "{  'details': {    'input_token_count': '8'  }}{  'tokens': [    {      'text': '▁',      'logprob': -1.2747352123260498    }  ],  'details': {    'generated_tokens': 1  }}{  'generated_text': '212',  'tokens': [    {      'text': '212',      'logprob': -1.0382558107376099    }  ],  'details': {    'generated_tokens': 2  }}{  'generated_text': ' ',  'tokens': [    {      'text': '▁',      'logprob': -0.8835393786430359    }  ],  'details': {    'generated_tokens': 3  }}{  'generated_text': '°',  'tokens': [    {      'text': '°',      'logprob': -0.6830151677131653    }  ],  'details': {    'generated_tokens': 4  }}{  'generated_text': ' ',  'tokens': [    {      'text': '▁',      'logprob': -0.8991543650627136    }  ],  'details': {    'generated_tokens': 5  }}{  'generated_text': 'f',  'tokens': [    {      'text': 'f',      'logprob': -0.44153422117233276    }  ],  'details': {    'generated_tokens': 6  }}{  'tokens': [    {      'text': '\u003c/s\u003e',      'logprob': -0.015602776780724525    }  ],  'details': {    'finish_reason': 'EOS_TOKEN',    'generated_tokens': 7  }}"
                },
                "mpt-7b-instruct2": {
                    "response_tokens": 20,
                    "response_text": "\nWater boils at 100 degrees Celsius (or 212 degrees Fahrenheit).\nWhat",
                    "streamed_response_text": "{    'inputTokenCount': 10}{    'generatedTokenCount': 2,    'text': '\n'}{    'generatedTokenCount': 3,    'text': 'I a'}{    'generatedTokenCount': 4,    'text': 'm no'}{    'generatedTokenCount': 5,    'text': 't sur'}{    'generatedTokenCount': 6,    'text': 'e i'}{    'generatedTokenCount': 7,    'text': 'f thi'}{    'generatedTokenCount': 8,    'text': 's i'}{    'generatedTokenCount': 9,    'text': 's th'}{    'generatedTokenCount': 10,    'text': 'e righ'}{    'generatedTokenCount': 11,    'text': 't plac'}{    'generatedTokenCount': 12,    'text': 'e t'}{    'generatedTokenCount': 13,    'text': 'o as'}{    'generatedTokenCount': 14,    'text': 'k thi'}{    'generatedTokenCount': 15,    'text': 's questio'}{    'generatedTokenCount': 16,    'text': 'n'}{    'generatedTokenCount': 17,    'text': ', bu'}{    'generatedTokenCount': 18,    'text': 't '}{    'generatedTokenCount': 19,    'text': 'I a'}{    'generatedTokenCount': 20,    'text': 'm trying',    'stopReason': 'MAX_TOKENS'}",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 7, 'tokens': [ 'At', 'Ġwhat', 'Ġtemperature', 'Ġdoes', 'Ġwater', 'Ġboil', '?' ] } ] }"
                    }
                }
            }
        },
        {
            "query_text": "This are an very wrong phraxe",
            "models": {
                "flan-t5-large-grammar-synthesis-caikit": {
                    "response_tokens":  9,
                    "response_text": "This is a very wrong phrase.",
                    "streamed_response_text":   "{'details':{'input_token_count':'10'}}{'generated_text':'This','tokens':[{'text':'▁This','logprob':<logprob_removed>}],'details':{'generated_tokens':1}}{'generated_text':'is','tokens':[{'text':'▁is','logprob':<logprob_removed>}],'details':{'generated_tokens':2}}{'generated_text':'','tokens':[{'text':'▁','logprob':<logprob_removed>}],'details':{'generated_tokens':3}}{'generated_text':'a','tokens':[{'text':'a','logprob':<logprob_removed>}],'details':{'generated_tokens':4}}{'generated_text':'very','tokens':[{'text':'▁very','logprob':<logprob_removed>}],'details':{'generated_tokens':5}}{'generated_text':'wrong','tokens':[{'text':'▁wrong','logprob':<logprob_removed>}],'details':{'generated_tokens':6}}{'generated_text':'phrase','tokens':[{'text':'▁phrase','logprob':<logprob_removed>}],'details':{'generated_tokens':7}}{'generated_text':'.','tokens':[{'text':'.','logprob':<logprob_removed>}],'details':{'generated_tokens':8}}{'tokens':[{'text':'</s>','logprob':<logprob_removed>}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':9}}"
                }
            }
        },
        {
            "query_text": "Elementary Watson! Translate to French",
            "models": {
                "mt0-xxl-hf": {
                    "response_tokens":  13,
                    "response_text": "Watson, c'est très simple !",
                    "streamed_response_text":   "{ 'inputTokenCount': 10 } { 'generatedTokenCount': 1, 'text': 'temperature' } { 'generatedTokenCount': 2, 'text': ' of' } { 'generatedTokenCount': 3, 'text': ' 180' } { 'generatedTokenCount': 4, 'text': ' ' } { 'generatedTokenCount': 5, 'text': '°' } { 'generatedTokenCount': 6, 'text': 'C' } { 'generatedTokenCount': 7, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime":{
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 9,       'tokens': [         '▁',         'Elementary',         '▁',         'Watson',         '!',         '▁Translate',         '▁to',         '▁French',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "translate English to German: How old are you?",
            "models":  {
                "flan-t5-xl-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 11,       'tokens': [         '▁translate',         '▁English',         '▁to',         '▁German',         ':',         '▁How',         '▁old',         '▁are',         '▁you',         '?',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                },
                "flan-t5-xxl-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 11, 'tokens': [ '▁translate', '▁English', '▁to', '▁German', ':', '▁How', '▁old', '▁are', '▁you', '?', '\u003c/s\u003e' ] } ] }"
                    }
                },
                "flan-ul2-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 11, 'tokens': [ '▁translate', '▁English', '▁to', '▁German', ':', '▁How', '▁old', '▁are', '▁you', '?', '\u003c/s\u003e' ] } ] }"
                    }

                }
            }
        },
        {
            "query_text": "桜の木についての話を書く",
            "models": {
                "elyza-japanese": {
                    "response_tokens":  20,
                    "response_text": "。\n桜の木は、桜の花が咲くと",
                    "streamed_response_text":   "{ 'inputTokenCount': 16 } { 'generatedTokenCount': 2, 'text': '。' } { 'generatedTokenCount': 5, 'text': '\n' } { 'generatedTokenCount': 6, 'text': '桜' } { 'generatedTokenCount': 7, 'text': 'の' } { 'generatedTokenCount': 8, 'text': '木' } { 'generatedTokenCount': 9, 'text': 'は' } { 'generatedTokenCount': 12, 'text': '、' } { 'generatedTokenCount': 13, 'text': '桜' } { 'generatedTokenCount': 14, 'text': 'の' } { 'generatedTokenCount': 15, 'text': '花' } { 'generatedTokenCount': 18, 'text': 'が' } { 'generatedTokenCount': 19, 'text': '咲' } { 'generatedTokenCount': 20, 'text': 'くと', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime":{
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 16,       'tokens': [         '\u003cs\u003e',         '▁',         '\u003c0xE6\u003e',         '\u003c0xA1\u003e',         '\u003c0x9C\u003e',         'の',         '木',         'に',         'つ',         'い',         'て',         'の',         '話',         'を',         '書',         'く'       ]     }   ] }"
                    }                
                }
            }
        },
        {
            "query_text": "write a python function to print the numbers from 1 to 10",
            "models": {
                "codellama-34b-instruct-hf": {
                    "response_tokens": 20,
                    "response_text": "0.\n\n\ndef print_numbers(n):\n    for i in range(1",
                    "streamed_response_text": "{'inputTokenCount':16}{'generatedTokenCount':2,'text':'0'}{'generatedTokenCount':3,'text':'.'}{'generatedTokenCount':4,'text':''}{'generatedTokenCount':5,'text':''}{'generatedTokenCount':6,'text':'de'}{'generatedTokenCount':7,'text':'fprin'}{'generatedTokenCount':8,'text':'t'}{'generatedTokenCount':9,'text':'_number'}{'generatedTokenCount':10,'text':'s'}{'generatedTokenCount':11,'text':'('}{'generatedTokenCount':12,'text':'n)'}{'generatedTokenCount':13,'text':':'}{'generatedTokenCount':14,'text':''}{'generatedTokenCount':15,'text':'fo'}{'generatedTokenCount':16,'text':'r'}{'generatedTokenCount':17,'text':'ii'}{'generatedTokenCount':18,'text':'nrang'}{'generatedTokenCount':19,'text':'e'}{'generatedTokenCount':20,'text':'(1','stopReason':'MAX_TOKENS'}"
                }
            }
        }
    ],
    "model-info": {
        "flan-t5-small-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-small-caikit": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "mt0-xxl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 2048, 'maxNewTokens': 1024 }"
        },
        "flan-t5-xl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-xxl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 2048, 'maxNewTokens': 1024 }"
        },
        "flan-ul2-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "elyza-japanese" : {
            "tgis-runtime": "{   'maxSequenceLength': 4096,   'maxNewTokens': 1024 }"
        },
        "mpt-7b-instruct2":{
            "tgis-runtime": "{     'maxSequenceLength': 2048,     'maxNewTokens': 1024   }"
        }
    }
}
