{
    "queries": [
        {
            "query_text": "At what temperature does water boil?",
            "models": {
                "flan-t5-small-caikit": {
                    "response_tokens":  5,
                    "response_text": "74 degrees F",
                    "streamed_response_text":   "{'details':{'input_token_count':'8'}}{'tokens':[{'text':'▁','logprob':-1.6961838006973267}],'details':{'generated_tokens':1}}{'generated_text':'74','tokens':[{'text':'74','logprob':-3.250730037689209}],'details':{'generated_tokens':2}}{'generated_text':'degrees','tokens':[{'text':'▁degrees','logprob':-0.4324559271335602}],'details':{'generated_tokens':3}}{'generated_text':'F','tokens':[{'text':'▁F','logprob':-1.361091136932373}],'details':{'generated_tokens':4}}{'tokens':[{'text':'\u003c/s\u003e','logprob':-0.010431881994009018}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':5}}",
                    "tgis-runtime":{
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 8, 'tokens': [ '▁At', '▁what', '▁temperature', '▁does', '▁water', '▁boil', '?', '\u003c/s\u003e' ] } ] }"
                    }
                },
                "flan-t5-small-hf": {
                    "response_tokens":  5,
                    "response_text": "74 degrees F",
                    "streamed_response_text":   "{'details':{'input_token_count':'8'}}{'tokens':[{'text':'▁','logprob':-1.6961838006973267}],'details':{'generated_tokens':1}}{'generated_text':'74','tokens':[{'text':'74','logprob':-3.250730037689209}],'details':{'generated_tokens':2}}{'generated_text':'degrees','tokens':[{'text':'▁degrees','logprob':-0.4324559271335602}],'details':{'generated_tokens':3}}{'generated_text':'F','tokens':[{'text':'▁F','logprob':-1.361091136932373}],'details':{'generated_tokens':4}}{'tokens':[{'text':'\u003c/s\u003e','logprob':-0.010431881994009018}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':5}}",
                    "tgis-runtime":{
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 8, 'tokens': [ '▁At', '▁what', '▁temperature', '▁does', '▁water', '▁boil', '?', '\u003c/s\u003e' ] } ] }"
                    }                },
                "bloom-560m-caikit": {
                    "response_tokens":  20,
                    "response_text": "The temperature of water boiling depends on the temperature of the water. The boiling point of water is the"
                },
                "flan-t5-large": {
                    "response_tokens":  7,
                    "response_text": "212 ° f",
                    "streamed_response_text":   "{  'details': {    'input_token_count': '8'  }}{  'tokens': [    {      'text': '▁',      'logprob': -1.2747352123260498    }  ],  'details': {    'generated_tokens': 1  }}{  'generated_text': '212',  'tokens': [    {      'text': '212',      'logprob': -1.0382558107376099    }  ],  'details': {    'generated_tokens': 2  }}{  'generated_text': ' ',  'tokens': [    {      'text': '▁',      'logprob': -0.8835393786430359    }  ],  'details': {    'generated_tokens': 3  }}{  'generated_text': '°',  'tokens': [    {      'text': '°',      'logprob': -0.6830151677131653    }  ],  'details': {    'generated_tokens': 4  }}{  'generated_text': ' ',  'tokens': [    {      'text': '▁',      'logprob': -0.8991543650627136    }  ],  'details': {    'generated_tokens': 5  }}{  'generated_text': 'f',  'tokens': [    {      'text': 'f',      'logprob': -0.44153422117233276    }  ],  'details': {    'generated_tokens': 6  }}{  'tokens': [    {      'text': '\u003c/s\u003e',      'logprob': -0.015602776780724525    }  ],  'details': {    'finish_reason': 'EOS_TOKEN',    'generated_tokens': 7  }}"
                },
                "mpt-7b-instruct2": {
                    "response_tokens": 20,
                    "response_text": "\nWater boils at 100 degrees Celsius (or 212 degrees Fahrenheit).\nWhat",
                    "streamed_response_text": "{'inputTokenCount': 7}{'generatedTokenCount': 2,'text': '\nWate'}{'generatedTokenCount': 3,'text': 'r b'}{'generatedTokenCount': 4,'text': 'oil'}{'generatedTokenCount': 5,'text': 's a'}{'generatedTokenCount': 6,'text': 't 10'}{'generatedTokenCount': 7,'text': '0 degree'}{'generatedTokenCount': 8,'text': 's '}{'generatedTokenCount': 9,'text': 'Cel'}{'generatedTokenCount': 10,'text': 'siu'}{'generatedTokenCount': 11,'text': 's '}{'generatedTokenCount': 12,'text': '(o'}{'generatedTokenCount': 13,'text': 'r 21'}{'generatedTokenCount': 14,'text': '2 degree'}{'generatedTokenCount': 15,'text': 's '}{'generatedTokenCount': 16,'text': 'Fahre'}{'generatedTokenCount': 17,'text': 'nhei'}{'generatedTokenCount': 18,'text': 't)'}{'generatedTokenCount': 19,'text': '.'}{'generatedTokenCount': 20,'text': '\nWhat','stopReason': 'MAX_TOKENS'}",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 7, 'tokens': [ 'At', 'Ġwhat', 'Ġtemperature', 'Ġdoes', 'Ġwater', 'Ġboil', '?' ] } ] }"
                    }
                },
                "llama-2-13b-chat": {
                    "response_tokens": 20,
                    "response_text": "\n\nWater boils at 100 degrees Celsius or 212",
                    "streamed_response_text": "{ 'inputTokenCount': 9 } { 'generatedTokenCount': 2, 'text': '\n' } { 'generatedTokenCount': 3, 'text': '\n' } { 'generatedTokenCount': 4, 'text': 'Wate' } { 'generatedTokenCount': 5, 'text': 'r b' } { 'generatedTokenCount': 6, 'text': 'oil' } { 'generatedTokenCount': 7, 'text': 's a' } { 'generatedTokenCount': 8, 'text': 't' } { 'generatedTokenCount': 9, 'text': ' ' } { 'generatedTokenCount': 10, 'text': '1' } { 'generatedTokenCount': 11, 'text': '0' } { 'generatedTokenCount': 12, 'text': '0 degree' } { 'generatedTokenCount': 13, 'text': 's Ce' } { 'generatedTokenCount': 14, 'text': 'ls' } { 'generatedTokenCount': 15, 'text': 'iu' } { 'generatedTokenCount': 16, 'text': 's o' } { 'generatedTokenCount': 17, 'text': 'r' } { 'generatedTokenCount': 18, 'text': ' ' } { 'generatedTokenCount': 19, 'text': '2' } { 'generatedTokenCount': 20, 'text': '12', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{'responses':[{'tokenCount':9,'tokens':['\\u003cs\\u003e','▁At','▁what','▁temperature','▁does','▁water','▁bo','il','?']}]}"
                    }
                }
            }
        },
        {
            "query_text": "This are an very wrong phraxe",
            "models": {
                "flan-t5-large-grammar-synthesis-caikit": {
                    "response_tokens":  9,
                    "response_text": "This is a very wrong phrase.",
                    "streamed_response_text":   "{'details':{'input_token_count':'10'}}{'generated_text':'This','tokens':[{'text':'▁This','logprob':<logprob_removed>}],'details':{'generated_tokens':1}}{'generated_text':'is','tokens':[{'text':'▁is','logprob':<logprob_removed>}],'details':{'generated_tokens':2}}{'generated_text':'','tokens':[{'text':'▁','logprob':<logprob_removed>}],'details':{'generated_tokens':3}}{'generated_text':'a','tokens':[{'text':'a','logprob':<logprob_removed>}],'details':{'generated_tokens':4}}{'generated_text':'very','tokens':[{'text':'▁very','logprob':<logprob_removed>}],'details':{'generated_tokens':5}}{'generated_text':'wrong','tokens':[{'text':'▁wrong','logprob':<logprob_removed>}],'details':{'generated_tokens':6}}{'generated_text':'phrase','tokens':[{'text':'▁phrase','logprob':<logprob_removed>}],'details':{'generated_tokens':7}}{'generated_text':'.','tokens':[{'text':'.','logprob':<logprob_removed>}],'details':{'generated_tokens':8}}{'tokens':[{'text':'</s>','logprob':<logprob_removed>}],'details':{'finish_reason':'EOS_TOKEN','generated_tokens':9}}"
                }
            }
        },
        {
            "query_text": "Elementary Watson! Translate to French",
            "models": {
                "mt0-xxl-hf": {
                    "response_tokens":  13,
                    "response_text": "Watson, c'est très simple !",
                    "streamed_response_text":   "{ 'inputTokenCount': 9 } { 'generatedTokenCount': 2, 'text': 'Watson' } { 'generatedTokenCount': 3, 'text': ',' } { 'generatedTokenCount': 4, 'text': ' c' } { 'generatedTokenCount': 5, 'text': \"'\" } { 'generatedTokenCount': 6, 'text': 'est' } { 'generatedTokenCount': 7, 'text': ' ' } { 'generatedTokenCount': 8, 'text': 'trè' } { 'generatedTokenCount': 9, 'text': 's' } { 'generatedTokenCount': 10, 'text': ' simple' } { 'generatedTokenCount': 11, 'text': ' ' } { 'generatedTokenCount': 12, 'text': '!' } { 'generatedTokenCount': 13, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime":{
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 9,       'tokens': [         '▁',         'Elementary',         '▁',         'Watson',         '!',         '▁Translate',         '▁to',         '▁French',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "translate English to German: How old are you?",
            "models":  {
                "flan-t5-xl-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 11,       'tokens': [         '▁translate',         '▁English',         '▁to',         '▁German',         ':',         '▁How',         '▁old',         '▁are',         '▁you',         '?',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                },
                "flan-t5-xxl-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 11, 'tokens': [ '▁translate', '▁English', '▁to', '▁German', ':', '▁How', '▁old', '▁are', '▁you', '?', '\u003c/s\u003e' ] } ] }"
                    }
                },
                "flan-ul2-hf": {
                    "response_tokens":  6,
                    "response_text": "Wie alt sind Sie?",
                    "streamed_response_text":   "{ 'inputTokenCount': 11 } { 'generatedTokenCount': 1, 'text': 'Wie' } { 'generatedTokenCount': 2, 'text': ' alt' } { 'generatedTokenCount': 3, 'text': ' sind' } { 'generatedTokenCount': 4, 'text': ' Sie' } { 'generatedTokenCount': 5, 'text': '?' } { 'generatedTokenCount': 6, 'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{ 'responses': [ { 'tokenCount': 11, 'tokens': [ '▁translate', '▁English', '▁to', '▁German', ':', '▁How', '▁old', '▁are', '▁you', '?', '\u003c/s\u003e' ] } ] }"
                    }

                }
            }
        },
        {
            "query_text": "桜の木についての話を書く",
            "models": {
                "elyza-japanese": {
                    "response_tokens":  20,
                    "response_text": "。\n桜の木は、桜の花が咲くと",
                    "streamed_response_text":   "{ 'inputTokenCount': 16 } { 'generatedTokenCount': 2, 'text': '。' } { 'generatedTokenCount': 5, 'text': '\n' } { 'generatedTokenCount': 6, 'text': '桜' } { 'generatedTokenCount': 7, 'text': 'の' } { 'generatedTokenCount': 8, 'text': '木' } { 'generatedTokenCount': 9, 'text': 'は' } { 'generatedTokenCount': 12, 'text': '、' } { 'generatedTokenCount': 13, 'text': '桜' } { 'generatedTokenCount': 14, 'text': 'の' } { 'generatedTokenCount': 15, 'text': '花' } { 'generatedTokenCount': 18, 'text': 'が' } { 'generatedTokenCount': 19, 'text': '咲' } { 'generatedTokenCount': 20, 'text': 'くと', 'stopReason': 'MAX_TOKENS' }",
                    "tgis-runtime":{
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 16,       'tokens': [         '\u003cs\u003e',         '▁',         '\u003c0xE6\u003e',         '\u003c0xA1\u003e',         '\u003c0x9C\u003e',         'の',         '木',         'に',         'つ',         'い',         'て',         'の',         '話',         'を',         '書',         'く'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "write a python function to print the numbers from 1 to 10",
            "models": {
                "codellama-34b-instruct-hf": {
                    "response_tokens": 20,
                    "response_text": "0.\n\n\ndef print_numbers(n):\n    for i in range(1",
                    "streamed_response_text": "{'inputTokenCount':16}{'generatedTokenCount':2,'text':'0'}{'generatedTokenCount':3,'text':'.'}{'generatedTokenCount':4,'text':''}{'generatedTokenCount':5,'text':''}{'generatedTokenCount':6,'text':'de'}{'generatedTokenCount':7,'text':'fprin'}{'generatedTokenCount':8,'text':'t'}{'generatedTokenCount':9,'text':'_number'}{'generatedTokenCount':10,'text':'s'}{'generatedTokenCount':11,'text':'('}{'generatedTokenCount':12,'text':'n)'}{'generatedTokenCount':13,'text':':'}{'generatedTokenCount':14,'text':''}{'generatedTokenCount':15,'text':'fo'}{'generatedTokenCount':16,'text':'r'}{'generatedTokenCount':17,'text':'ii'}{'generatedTokenCount':18,'text':'nrang'}{'generatedTokenCount':19,'text':'e'}{'generatedTokenCount':20,'text':'(1','stopReason':'MAX_TOKENS'}"
                }
            }
        },
        {
            "query_text": "I am frustrated because of long wait times and unresponsive helpdesk teams, causing delays in issue resolution.",
            "models": {
                "flan-t5-xl-hf-ptuned": {
                    "response_tokens": 2,
                    "response_text": "complaint",
                    "streamed_response_text": "{   'inputTokenCount': 24 } {   'generatedTokenCount': 1,   'text': 'complaint' } {   'generatedTokenCount': 2,   'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": "{   'responses': [     {       'tokenCount': 24,       'tokens': [         '▁I',         '▁am',         '▁frustrated',         '▁because',         '▁of',         '▁long',         '▁wait',         '▁times',         '▁and',         '▁un',         'responsive',         '▁help',         'des',         'k',         '▁teams',         ',',         '▁',         'causing',         '▁delays',         '▁in',         '▁issue',         '▁resolution',         '.',         '\u003c/s\u003e'       ]     }   ] }"
                    }
                }
            }
        },
        {
            "query_text": "I am delighted to see how much helpful the helpdesk team is.",
            "models": {
                "flan-t5-xl-hf-ptuned": {
                    "response_tokens": 3,
                    "response_text": "no complaint",
                    "streamed_response_text": "{   'inputTokenCount': 16 } {   'generatedTokenCount': 1,   'text': 'no' } {   'generatedTokenCount': 2,   'text': ' complaint' } {   'generatedTokenCount': 3,   'stopReason': 'EOS_TOKEN' }",
                    "tgis-runtime": {
                        "tokenize_response_text": ""
                    }
                }
            }
        }
    ],
    "model-info": {
        "flan-t5-small-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-small-caikit": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "mt0-xxl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 2048, 'maxNewTokens': 1024 }"
        },
        "flan-t5-xl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-xl-hf-ptuned": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "flan-t5-xxl-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 2048, 'maxNewTokens': 1024 }"
        },
        "flan-ul2-hf": {
            "tgis-runtime": "{ 'modelKind': 'ENCODER_DECODER', 'maxSequenceLength': 512, 'maxNewTokens': 511 }"
        },
        "elyza-japanese" : {
            "tgis-runtime": "{   'maxSequenceLength': 4096,   'maxNewTokens': 1024 }"
        },
        "mpt-7b-instruct2":{
            "tgis-runtime": "{     'maxSequenceLength': 2048,     'maxNewTokens': 1024   }"
        },
        "llama-2-13b-chat-hf":{
            "tgis-runtime": "{ 'maxSequenceLength': 4096,'maxNewTokens': 1024}"
        }
    }
}
